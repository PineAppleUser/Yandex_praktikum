{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Шаг 1: Открыть и изучить файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "import pandas as pd\n",
    "\n",
    "#for splitting the data and counting score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#importing models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#for checking of adequacy\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/Users/DanilBee/Desktop/Yandex_projects/mlTariffs/users_behavior.csv')\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увидел ,что данные все в правильном формате , то есть числовые и переменную ,которую нужно предсказывать в формате 1/0 , а не True/False. Так что готовы решать задачу бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Шаг 2: Разбить на выборки</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into 2 sets 60% for the training and 40% for the test and validation\n",
    "train_df, test_df = train_test_split(df, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting these 40% by half for the test and validation\n",
    "test_df, valid_df = train_test_split(test_df, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина выборки тренировки : 1928\n",
      "Длина выборки теста : 643\n",
      "Длина выборки валидации : 643\n"
     ]
    }
   ],
   "source": [
    "print('Длина выборки тренировки :', train_df.shape[0])\n",
    "print('Длина выборки теста :', test_df.shape[0])\n",
    "print('Длина выборки валидации :', valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making features and target for each set\n",
    "\n",
    "#train's features and target\n",
    "train_features = train_df.drop('is_ultra', axis = 1)\n",
    "train_target = train_df['is_ultra']\n",
    "\n",
    "#test's features and target\n",
    "test_features = test_df.drop('is_ultra', axis = 1)\n",
    "test_target = test_df['is_ultra']\n",
    "\n",
    "#validation's features and target\n",
    "valid_features = valid_df.drop('is_ultra', axis = 1)\n",
    "valid_target = valid_df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбили на 3 выборки , то есть дали 60 % данных на тренировку модели , и остальные 40% поделили поровну между валидационной выборкой и тестовой. Также для каждой выборки поделили данные на: признаки и на целевой признак"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Шаг 3: Исследовать данные на выборки</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy for Decision Tree on validation set = 0.7869362363919129 with the 6 max depth\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree model\n",
    "best = 0\n",
    "i = 0\n",
    "for index in range(1,50,1):\n",
    "    treeModel = DecisionTreeClassifier(max_depth = index ,random_state = 42)\n",
    "    \n",
    "    treeModel.fit(train_features, train_target)\n",
    "    \n",
    "    treePrediction = treeModel.predict(valid_features)\n",
    "    \n",
    "    acc = accuracy_score(valid_target,treePrediction)\n",
    "    \n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        i = index\n",
    "print('best accuracy for Decision Tree on validation set =',best,'with the {} max depth'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy for Random Forest on validation set = 0.8211508553654744 with the 12 estimators and depth =  8\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "i = 0\n",
    "d = 0\n",
    "for estim in range (1, 50, 1):\n",
    "    for depth in range(1, 10 ,1):\n",
    "        forestModel = RandomForestClassifier(max_depth = depth,n_estimators = estim, random_state = 42)\n",
    "    \n",
    "        forestModel.fit(train_features, train_target)\n",
    "    \n",
    "        forestPrediction = forestModel.predict(valid_features)\n",
    "    \n",
    "        acc = accuracy_score(valid_target, forestPrediction)\n",
    "    \n",
    "        if acc > best:\n",
    "            best = acc\n",
    "            i = estim\n",
    "            d = depth\n",
    "print('best accuracy for Random Forest on validation set =',best,'with the {} estimators'.format(i),'and depth = ',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследовали данные на выборках и исследовали только на 2 моделях , так как в них мы исследуем поведение модели от гиперпараметров ,которые мы меняем в цикле и ищем лучшие показатели. Также в случае со случайным лесом провели достаточно емкое обучение , но у нас нету задачи повысить скорость , а ,скорей, проделать более емкое исследование,поэтому проводил исследование по комбинации 2 гиперпараметров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Шаг 4: Проверить модели на тестовой выборки</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of RandomForest on the testing data is: 0.8055987558320373\n"
     ]
    }
   ],
   "source": [
    "#checking for the effectivness of parameters figured out on validation set for the RandomForestClassifier\n",
    "forestModel = RandomForestClassifier(max_depth = 8, n_estimators = 49, random_state = 42)\n",
    "forestModel.fit(train_features, train_target)\n",
    "predFMtest = forestModel.predict(test_features)\n",
    "print(\"Score of RandomForest on the testing data is:\", accuracy_score(test_target, predFMtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of DecisionTree on the testing data is: 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "#checking for the effectivness of parameters figured out on validation set for the DecisionTreeClassifier\n",
    "treeModel = DecisionTreeClassifier(max_depth = 3, random_state = 42)\n",
    "treeModel.fit(train_features, train_target)\n",
    "predTMtest = treeModel.predict(test_features)\n",
    "print(\"Score of DecisionTree on the testing data is:\", accuracy_score(test_target, predTMtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of LogisticRegression on the testing data is: 0.6911917098445596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#we don't tweak any parameters in Logistic Regresson \n",
    "#so we actually can instead of tweaking - just make training and testing sets \n",
    "#and improve the accuracy that way so we have more data to train the model\n",
    "trainLR_df, testLR_df = train_test_split(df, test_size = 0.3)\n",
    "\n",
    "trainLR_features = trainLR_df.drop('is_ultra', axis = 1)\n",
    "trainLR_target = trainLR_df['is_ultra']\n",
    "testLR_features = testLR_df.drop('is_ultra', axis = 1)\n",
    "testLR_target = testLR_df['is_ultra']\n",
    "\n",
    "logisticModel = LogisticRegression(random_state = 42)\n",
    "\n",
    "logisticModel.fit(trainLR_features, trainLR_target)\n",
    "\n",
    "predLRtest = logisticModel.predict(testLR_features)\n",
    "\n",
    "print(\"Score of LogisticRegression on the testing data is:\", accuracy_score(testLR_target, predLRtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель после исследования не дала переобучаемость , ведь сохранила достаточно близку точность на тестовых данных к валидационным. В случае с логистической регрессией , для нее провели отдельный тест , так как она не нужная в валидационных данных , ведь там нету гиперпараметров , поэтому можно улучшить ее точность за счет увелечения объема данных , не используя валидационный сет. Таким образом получили 3 достаточно точных модели , где фаворитом в качестве выступает Случайный лес 79%, но с наименьшей скоростью. Не сильно ему уступает также Дерево решений 78% и логистическая регрессия еле как набрала необходимый результат 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Шаг 5: Проверить модели на адекватность</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent correct answer model will have accuracy of 0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "#training the dummy model to compare\n",
    "dummyModel = DummyClassifier(strategy = 'most_frequent',random_state = 42)\n",
    "dummyModel.fit(train_features, train_target)\n",
    "predDummytest = dummyModel.predict(test_features)\n",
    "print('The most frequent correct answer model will have accuracy of', accuracy_score(test_target,predDummytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как логистическую регрессию тренировали и проверяли с другим объемом данных - поменяем на такие же объемы данных как и в ней для модели проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent correct answer model will have accuracy of 0.6860103626943005\n"
     ]
    }
   ],
   "source": [
    "dummyModel2 = DummyClassifier(strategy = 'most_frequent',random_state = 42)\n",
    "dummyModel2.fit(trainLR_features, trainLR_target)\n",
    "predDummytest2 = dummyModel2.predict(testLR_features)\n",
    "print('The most frequent correct answer model will have accuracy of', accuracy_score(testLR_target,predDummytest2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из первой простой модели для сравнения Дерева решений и Случайного леса получили ,что обе модели адекватные 78% и 79%  против 68% у простой модели. Так как для логистической использовали другой подход - создали вторую просту модель на основе объема логистической регрессии и также получили ,что логистическая модель прошла проверку на адекватность 75% против 69%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
